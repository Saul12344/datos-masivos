<p align="center">
    <img alt="Logo" src="https://www.tijuana.tecnm.mx/wp-content/uploads/2021/08/liston-de-logos-oficiales-educacion-tecnm-FEB-2021.jpg" width=850 height=250>
</p>
<H2><p align="center">Unit#4 branch. Big Data course.</p></H2>
<H2><p align="Center">STUDENT'S NAMES: </p></H2>

<H2><p align="Center">López Higuera Saúl Alfredo #18210493</p></H2>

<H2><p align="Center">Ramos Rivera Manuel Isaí #17212931</p></H2>
<H2><p align="Center">LINK DEL VIDEO:https://www.youtube.com/watch?v=eLcprAHl5yA</p></H2>

# Final project

# Introduction.
This is the final evaluation of the subject of massive data, in this practice it is intended to see how effective the learning models are, comparing the memory they use, the time they take to execute and seeing their precision, this will be done with a file csv provided by the teacher that has more than 45,000 data.
The objective of the classification is to predict if the client subscribed a term deposit (variable y) and we try to make a prediction with the models: SVM, decision tree, logistic regression and multilayer perceptron that are machine learning models.


# Theoretical framework of algorithms.

- Decision Three
- Logistic Regression
- Multilayer perceptron
- Support Vector Machine (SVM)


# Support Vector Machine (SVM).

It is a discriminative classifier formally defined by a separation hyperplane. In other words, given the labeled training data (supervised learning), the algorithm generates an optimal hyperplane that categorizes new examples. In two-dimensional spaces, this hyperplane is a line that divides a plane into two parts where each class is on each side. That is used in many classification and regression problems, including medical applications of signal processing, natural language processing, and image and speech recognition. The idea of SVM is simple: the algorithm creates a line or hyperplane that separates the data into classes.

![logo](/Img/1.PNG)  

Advantages and disadvantages

Advantage:
- Classifier algorithm based on solid theory. Risk minimization theorems are the state of the art in statistical learning.
- Can be applied to data represented in any Hilbert space (where you can define a distance measure).
- Relatively few parameters to estimate.
- New extensions can be formulated (flexibility).

Disadvantages:
- Determining the kernels to use is complex.
- It is just a binary classifier.

## Code
  ~~~

  ~~~
![logo](/images/E1.PNG)  
  ~~~

 ~~~
![logo](/images/E2.PNG)  
  ~~~

 ~~~
![logo](/images/E3.PNG)  
  ~~~

 ~~~
![logo](/images/E4.PNG)  
  ~~~

 ~~~
![logo](/images/E5.PNG)  
  ~~~



 ~~~
